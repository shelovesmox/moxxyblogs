<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Start of My PX Reverse Journey | My New Hugo Site</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="So, I decided to start my RE journey by reverse engineering Perimeter X. Currently, I am working on the site grubhub.com and have also checked out a site called airtable.com. Mind you, I have heard about many anti-bots but never brought myself to actually attempt reversing them. From PX to Cloudflare, Shape, and other services like Akamai and Kasada, they have always interested me. It&rsquo;s from both an egotistical perspective and pure curiosity about how they work and whether I can reverse engineer them to bypass their protections.">
    <meta name="generator" content="Hugo 0.113.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Start of My PX Reverse Journey" />
<meta property="og:description" content="So, I decided to start my RE journey by reverse engineering Perimeter X. Currently, I am working on the site grubhub.com and have also checked out a site called airtable.com. Mind you, I have heard about many anti-bots but never brought myself to actually attempt reversing them. From PX to Cloudflare, Shape, and other services like Akamai and Kasada, they have always interested me. It&rsquo;s from both an egotistical perspective and pure curiosity about how they work and whether I can reverse engineer them to bypass their protections." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/posts/start-of-my-px-reverse-journey/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-08T14:09:01-04:00" />
<meta property="article:modified_time" content="2023-06-08T14:09:01-04:00" />
<meta itemprop="name" content="Start of My PX Reverse Journey">
<meta itemprop="description" content="So, I decided to start my RE journey by reverse engineering Perimeter X. Currently, I am working on the site grubhub.com and have also checked out a site called airtable.com. Mind you, I have heard about many anti-bots but never brought myself to actually attempt reversing them. From PX to Cloudflare, Shape, and other services like Akamai and Kasada, they have always interested me. It&rsquo;s from both an egotistical perspective and pure curiosity about how they work and whether I can reverse engineer them to bypass their protections."><meta itemprop="datePublished" content="2023-06-08T14:09:01-04:00" />
<meta itemprop="dateModified" content="2023-06-08T14:09:01-04:00" />
<meta itemprop="wordCount" content="360">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Start of My PX Reverse Journey"/>
<meta name="twitter:description" content="So, I decided to start my RE journey by reverse engineering Perimeter X. Currently, I am working on the site grubhub.com and have also checked out a site called airtable.com. Mind you, I have heard about many anti-bots but never brought myself to actually attempt reversing them. From PX to Cloudflare, Shape, and other services like Akamai and Kasada, they have always interested me. It&rsquo;s from both an egotistical perspective and pure curiosity about how they work and whether I can reverse engineer them to bypass their protections."/>

	
  </head>

  <body class="ma0 sans-serif">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('/images/analysis.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div style="gap: 20px;" class="flex-l items-center center">
    <a style="font-weight: 500;" href="/" class="f5 fw2 hover-white no-underline white-90 dib">
      Home
    </a>
    <a style="font-weight: 500;" target="_blank" href="https://github.com/shelovesmox" class="f5 fw2 hover-white no-underline white-90 dib nav-item">
      Github
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

<style>
  @media (max-width: 768px) {
    .nav-item {
      font-weight: 500;
      padding-left: 20px;
    }
  }
</style>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div style="text-align: center;" class="f2 f1-l fw7 white-90 mb0 lh-title">Start of My PX Reverse Journey</div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f2 mt3 mb1">Start of My PX Reverse Journey</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-06-08T14:09:01-04:00">June 8, 2023</time>
      

      
      
    </header>
    <div class="nested-copy-line-height w-full lh-copy sans-serif f4 nested-links mid-gray pr4-l"><p>So, I decided to start my RE journey by reverse engineering Perimeter X. Currently, I am working on the site grubhub.com and have also checked out a site called airtable.com. Mind you, I have heard about many anti-bots but never brought myself to actually attempt reversing them. From PX to Cloudflare, Shape, and other services like Akamai and Kasada, they have always interested me. It&rsquo;s from both an egotistical perspective and pure curiosity about how they work and whether I can reverse engineer them to bypass their protections. I have always loved the idea of bypassing security. I&rsquo;m not sure why. The greatness it is to reverse engineer the anti-bots of multimillion-dollar companies is, at the very least, a very nice feeling.</p>
<p>Anyways, enough about me and on to my findings for the day. I set out on this journey to learn completely on my own, without referencing others&rsquo; work, especially when it comes to PX reverse engineering. All findings documented on my journey have been discovered by me through hours of analysis. This is my journey documented. I&rsquo;m not here to teach anyone reverse engineering, nor am I here to guide anyone, as I am not experienced enough to be a teacher of any sort, and I&rsquo;ve just started, lmao, If you have some itch about something I said being wrong or incorrect, please do educate me as im trying to learn, otherwise again this is my journey so I will not get everything right first try. But I will make an effort to make what I&rsquo;m saying and found understandable.</p>
<h4 id="analyzing-px-scripts-and-request-payloads">Analyzing PX Scripts And Request Payloads</h4>
<ul>
<li>
<h5 id="px-scripts-location">PX Scripts Location</h5>
</li>
</ul>
<p>The Perimeter X scripts (and really any scripts) are located in the Sources tab of the Chrome DevTools in your browser.</p>
<p><img src="/images/pxscriptloc.png" alt="PX Script Location"></p>
<ul>
<li>
<h5 id="taking-a-look-at-request-payloads-and-responses">Taking a Look At Request Payloads And Responses</h5>
</li>
</ul>
<p>So, of course, being my first time doing this, I didn&rsquo;t really know what to do. But, of course, I figured that I need to look at the requests because, well, this is a website, and requests are how data is sent and received. So, I open up the Network tab in Chrome DevTools and begin looking at the requests.</p>
<p align="center">
  <img src="/images/grubhubreq.png" />
</p
<p>Let&rsquo;s actually dissect what is important and what isn&rsquo;t. The first request is simply the <strong>GET</strong> request that&rsquo;s made when you load up the page on Grubhub. We can ignore everything else until we get to a request named &ldquo;collector&rdquo;. This is the first request made by Perimeter X, and it is the request that is sent multiple times, interacting and communicating with PX. The payload changes each time, but some things stay static from the first request all the way to the end.</p>
<p align="center">
  <img src="/images/collector.png" />
</p
<p>This is a POST request to the endpoint <code>https://sensor.grubhub.com/O97ybH4J/xhr/api/v2/collector</code>. <code>https://sensor.grubhub.com</code> is the endpoint/domain that Grubhub uses to communicate with PX.</p>
<p align="center">
  <img src="/images/payload.png" />
</p
<p>What I discovered from looking at the PX Scripts is that the appId is unique to each website. It is essentially an identifier to verify that the request is coming from a PX certified user. ðŸ˜‰</p>
<p>This is the PX App ID for Grubhub:</p>
<p align="center">
  <img src="/images/appId.png" />
</p
<p>And this is the PX App ID for airtable.com:</p>
<p align="center">
  <img src="/images/airtableappid.png" />
</p
<p>As you can see, they are essentially the same thing. However, note that both of these are at different versions (as shown by the license copyright date), so the script will not be the same. But as for this part of the script, not much has changed.</p>
<ul>
<li>
<h4 id="final-analysis-for-the-day">Final Analysis for the Day</h4>
</li>
</ul>
<p>Overall, this was the conclusion I came to after my first few hours (2 hours) of looking at the interaction between Grubhub and PX.</p>
<p align="center">
  <img src="/images/analysis.png" />
</p
<p>Again, I apologize if this wasn&rsquo;t the most comprehensive analysis, but this is for my learning experience and to document my journey. Thank you for reading!</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://example.org/" >
    &copy; Mox Blog 2023
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
